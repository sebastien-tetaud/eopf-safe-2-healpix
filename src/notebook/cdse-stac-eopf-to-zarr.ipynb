{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Sentinel-2 Data from the Copernicus Data Space Ecosystem\n",
    "\n",
    "This notebook demonstrates how to access and process Sentinel-2 satellite imagery from the Copernicus Data Space Ecosystem using both S3 and STAC interfaces.\n",
    "\n",
    "### What you'll learn:\n",
    "- How to connect to Copernicus Data Space Ecosystem using S3 credentials\n",
    "- How to search for satellite imagery using STAC API\n",
    "- Download CDSE .SAFE product\n",
    "- Convert SAFE file into a Zarr product\n",
    "- Download and transform on the fly .SAFE product into Zarr product\n",
    "- How to download and visualize Sentinel-2 imagery\n",
    "\n",
    "### Prerequisites:\n",
    "- Copernicus Data Space Ecosystem account (https://dataspace.copernicus.eu/)\n",
    "- Access and secret keys configured in environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import random\n",
    "\n",
    "import boto3\n",
    "import pystac_client\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Environment Configuration\n",
    "\n",
    "First, we'll import the required libraries and set up our environment. Make sure your Copernicus credentials are stored in your environment variables or a `.env` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get credentials from environment variables\n",
    "load_dotenv()\n",
    "ACCESS_KEY_ID = os.environ.get(\"ACCESS_KEY_ID\")\n",
    "SECRET_ACCESS_KEY = os.environ.get(\"SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The S3Connector Class\n",
    "\n",
    "The `S3Connector` class provides an interface to connect to the S3-compatible storage service of the Copernicus Data Space Ecosystem. This class handles authentication and connection management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3Connector:\n",
    "    \"\"\"A clean connector for S3-compatible storage services\"\"\"\n",
    "\n",
    "    def __init__(self, endpoint_url, access_key_id,\n",
    "                 secret_access_key, region_name='default'):\n",
    "        \"\"\"Initialize the S3Connector with connection parameters\"\"\"\n",
    "        self.endpoint_url = endpoint_url\n",
    "        self.access_key_id = access_key_id\n",
    "        self.secret_access_key = secret_access_key\n",
    "        self.region_name = region_name\n",
    "\n",
    "        # Create session\n",
    "        self.session = boto3.session.Session()\n",
    "\n",
    "        # Initialize S3 resource\n",
    "        self.s3 = self.session.resource(\n",
    "            's3',\n",
    "            endpoint_url=self.endpoint_url,\n",
    "            aws_access_key_id=self.access_key_id,\n",
    "            aws_secret_access_key=self.secret_access_key,\n",
    "            region_name=self.region_name\n",
    "        )\n",
    "\n",
    "        # Initialize S3 client\n",
    "        self.s3_client = self.session.client(\n",
    "            's3',\n",
    "            endpoint_url=self.endpoint_url,\n",
    "            aws_access_key_id=self.access_key_id,\n",
    "            aws_secret_access_key=self.secret_access_key,\n",
    "            region_name=self.region_name\n",
    "        )\n",
    "\n",
    "    def get_s3_client(self):\n",
    "        \"\"\"Get the boto3 S3 client\"\"\"\n",
    "        return self.s3_client\n",
    "\n",
    "    def get_s3_resource(self):\n",
    "        \"\"\"Get the boto3 S3 resource\"\"\"\n",
    "        return self.s3\n",
    "\n",
    "    def get_bucket(self, bucket_name):\n",
    "        \"\"\"Get a specific bucket by name\"\"\"\n",
    "        return self.s3.Bucket(bucket_name)\n",
    "\n",
    "    def list_buckets(self):\n",
    "        \"\"\"List all available buckets\"\"\"\n",
    "        response = self.s3_client.list_buckets()\n",
    "        if 'Buckets' in response:\n",
    "            return [bucket['Name'] for bucket in response['Buckets']]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "The following function helps convert S3 URIs from the STAC catalog into S3 keys that can be used for direct access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_s3_path_from_url(url):\n",
    "    \"\"\"\n",
    "    Extracts the S3 object path from an S3 URL or URI.\n",
    "\n",
    "    This function parses S3 URLs/URIs and returns just the object path portion,\n",
    "    removing the protocol (s3://), bucket name, and any leading slashes.\n",
    "\n",
    "    Args:\n",
    "        url (str): The full S3 URI (e.g., 's3://eodata/path/to/file.jp2')\n",
    "\n",
    "    Returns:\n",
    "        str: The S3 object path (without protocol, bucket name and leading slashes)\n",
    "    \"\"\"\n",
    "    # If it's not an S3 URI, return it unchanged\n",
    "    if not url.startswith('s3://'):\n",
    "        return url\n",
    "\n",
    "    # Parse the S3 URI\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    # Ensure this is an S3 URL\n",
    "    if parsed_url.scheme != 's3':\n",
    "        raise ValueError(f\"URL {url} is not an S3 URL\")\n",
    "\n",
    "    # Extract the path without leading slashes\n",
    "    object_path = parsed_url.path.lstrip('/')\n",
    "\n",
    "    return object_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product(s3_resource, bucket_name, object_url, output_path):\n",
    "    \"\"\"\n",
    "    Download a product from S3 bucket and create output directory if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "        s3_resource: boto3 S3 resource object\n",
    "        bucket_name (str): Name of the S3 bucket\n",
    "        object_url (str): Path to the object within the bucket\n",
    "        output_path (str): Local directory to save the file\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the downloaded file\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Extract filename from the object URL\n",
    "    _, filename = os.path.split(object_url)\n",
    "\n",
    "    # Full path where the file will be saved\n",
    "    local_file_path = os.path.join(output_path, filename)\n",
    "\n",
    "    print(f\"Downloading {object_url} to {local_file_path}...\")\n",
    "\n",
    "    try:\n",
    "        # Download the file from S3\n",
    "        s3_resource.Bucket(bucket_name).download_file(object_url, local_file_path)\n",
    "        print(f\"Successfully downloaded to {local_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    return local_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Copernicus Data Space Ecosystem\n",
    "\n",
    "Now let's establish connections to both the S3 storage and STAC catalog services using our credentials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY_ID = os.environ.get(\"ACCESS_KEY_ID\")\n",
    "SECRET_ACCESS_KEY = os.environ.get(\"SECRET_ACCESS_KEY\")\n",
    "ENDPOINT_URL = 'https://eodata.dataspace.copernicus.eu'\n",
    "ENDPOINT_STAC = \"https://stac.dataspace.copernicus.eu/v1/\"\n",
    "BUCKET_NAME = \"eodata\"\n",
    "catalog = pystac_client.Client.open(ENDPOINT_STAC)\n",
    "connector = S3Connector(\n",
    "    endpoint_url=ENDPOINT_URL,\n",
    "    access_key_id=ACCESS_KEY_ID,\n",
    "    secret_access_key=SECRET_ACCESS_KEY,\n",
    "    region_name='default'\n",
    ")\n",
    "# Get S3 client and resource from the connector instance\n",
    "s3 = connector.get_s3_resource()\n",
    "s3_client = connector.get_s3_client()\n",
    "buckets = connector.list_buckets()\n",
    "print(\"Available buckets:\", buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for Sentinel-2 Product\n",
    "\n",
    "We'll use the STAC API to search for Sentinel-2 Level 2A products based on:\n",
    "- Geographic location (longitude/latitude point)\n",
    "- Date range\n",
    "- Cloud cover threshold\n",
    "\n",
    "The search results provide metadata and access links to the actual imagery.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LON, LAT = 150.97, -20.92\n",
    "# Search for Sentinel-2 products\n",
    "items_txt = catalog.search(\n",
    "    collections=['sentinel-2-l1c'],\n",
    "    intersects=dict(type=\"Point\", coordinates=[LON, LAT]),\n",
    "    datetime=\"2024-05-01/2024-06-01\",\n",
    "    query=[\"eo:cloud_cover<50\"]\n",
    ").item_collection()\n",
    "selected_item = random.choice(items_txt)\n",
    "selected_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundinx Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bounding box coordinates [min_lon, min_lat, max_lon, max_lat]\n",
    "min_lon, min_lat, max_lon, max_lat = 150.95,-20.92, 150.97, -20.95  # Example: 1Â° box around LON=15, LAT=50\n",
    "\n",
    "# Create a bounding box polygon (must be closed, so repeat the first point at the end)\n",
    "bbox_polygon = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [[\n",
    "        [min_lon, min_lat],  # Southwest corner\n",
    "        [max_lon, min_lat],  # Southeast corner\n",
    "        [max_lon, max_lat],  # Northeast corner\n",
    "        [min_lon, max_lat],  # Northwest corner\n",
    "        [min_lon, min_lat]   # Close the polygon by repeating the first point\n",
    "    ]]\n",
    "}\n",
    "\n",
    "# Search for Sentinel-2 products within the bounding box\n",
    "items_txt = catalog.search(\n",
    "    collections=['sentinel-2-l2a'],\n",
    "    intersects=bbox_polygon,\n",
    "    datetime=\"2024-05-01/2024-06-01\",\n",
    "    query=[\"eo:cloud_cover<10\"]\n",
    ").item_collection()\n",
    "selected_item = random.choice(items_txt)\n",
    "selected_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Sentinel-2 Product\n",
    "\n",
    "Once we've identified the product we want, we can download it using our S3 connection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(bucket, product: str, target: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Downloads every file in the S3 bucket with the provided product prefix.\n",
    "    Creates a local folder named after the .SAFE directory (without the .SAFE extension).\n",
    "\n",
    "    Args:\n",
    "        bucket: boto3 Resource bucket object\n",
    "        product: Path to the product (e.g., 'Sentinel-2/MSI/L2A/.../S2B_MSIL2A_..._T56KKB_20240516T015827.SAFE/')\n",
    "        target: Local directory to save the files. Defaults to current directory.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the downloaded .SAFE directory (without the .SAFE extension)\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the product was not found in the bucket\n",
    "    \"\"\"\n",
    "    # Ensure the product path ends with '/'\n",
    "    if not product.endswith('/'):\n",
    "        product += '/'\n",
    "\n",
    "    # List files in the S3 prefix\n",
    "    files = list(bucket.objects.filter(Prefix=product))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"Could not find any files for {product}\")\n",
    "\n",
    "    # Extract the .SAFE directory name (e.g., \"S2B_MSIL2A_20240516T001109_N0510_R073_T56KKB_20240516T015827.SAFE\")\n",
    "    safe_dir = os.path.basename(product.rstrip('/'))\n",
    "    if not safe_dir.endswith('.SAFE'):\n",
    "        raise ValueError(f\"Expected a .SAFE directory, got: {safe_dir}\")\n",
    "\n",
    "    # Create the local target directory (without the .SAFE extension)\n",
    "    # local_dir = safe_dir[:-5]  # Remove '.SAFE' from the name\n",
    "    local_path = os.path.join(target, safe_dir)\n",
    "\n",
    "    # Create the local directory structure\n",
    "    os.makedirs(local_path, exist_ok=True)\n",
    "\n",
    "    # Download each file while preserving the relative structure\n",
    "    for file in files:\n",
    "        # Skip directory markers (S3 pseudo-folders)\n",
    "        if file.key.endswith('/'):\n",
    "            continue\n",
    "\n",
    "        # Compute the relative path inside the .SAFE directory\n",
    "        relative_path = os.path.relpath(file.key, product)\n",
    "        local_file_path = os.path.join(local_path, relative_path)\n",
    "\n",
    "        # Create parent directories if they don't exist\n",
    "        os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "\n",
    "        # Download the file\n",
    "        bucket.download_file(file.key, local_file_path)\n",
    "\n",
    "    return local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = random.choice(items_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "product_url , _ = os.path.split(selected_item.assets['safe_manifest'].href)\n",
    "product_url = extract_s3_path_from_url(product_url)\n",
    "safe_filename = download(bucket, product_url, target=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# Replace .SAFE with .zarr\n",
    "zarr_filename =  os.path.split(safe_filename)[1].replace('.SAFE', '.zarr')\n",
    "# Join the current directory path with the new filename\n",
    "zarr_path = os.path.join(current_dir, zarr_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EOPF converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting a local legacy product (safe format) into new Zarr format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eopf.store.convert import convert\n",
    "\n",
    "convert(safe_filename, zarr_path, mask_and_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_filename = download(bucket, product_url, target=\".\")\n",
    "convert(safe_filename, zarr_path, mask_and_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "dt = xr.open_datatree(zarr_path, engine=\"zarr\", mask_and_scale=False, chunks={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = dt.measurements.reflectance.r10m\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "rgb = np.dstack([\n",
    "    ds['b04'].values,\n",
    "    ds['b03'].values,\n",
    "    ds['b02'].values\n",
    "])\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(rgb)\n",
    "plt.axis('off')\n",
    "plt.title('Sentinel-2 RGB Composite')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and transform on the flight from S3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and convert a legacy product (safe format) into new Zarr format locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_url , _ = os.path.split(selected_item.assets['safe_manifest'].href)\n",
    "# Replace .SAFE with .zarr\n",
    "zarr_filename =  os.path.split(product_url)[1].replace('.SAFE', '.zarr')\n",
    "# Join the current directory path with the new filename\n",
    "zarr_path = os.path.join(current_dir, zarr_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eopf.common.constants import OpeningMode\n",
    "from eopf.common.file_utils import AnyPath\n",
    "\n",
    "S3_CONFIG = {\n",
    "    \"key\": ACCESS_KEY_ID, # EDIT WITH YOUR S3 KEY\n",
    "    \"secret\": SECRET_ACCESS_KEY, # EDIT WITH YOUR S3 SECRET KEY\n",
    "    \"client_kwargs\": { \"endpoint_url\": ENDPOINT_URL, \"region_name\": \"default\"} # EDIT WITH YOUR CLIENT_KWARGS\n",
    "}\n",
    "# Add this parameter if you want to overwrite the output of the conversion if it already exists\n",
    "target_store_config = dict(mode=OpeningMode.CREATE_OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the zarr store we don't need to add the storage_options argument because we want to write the target product locally\n",
    "convert(AnyPath(product_url, **S3_CONFIG), zarr_path, target_store_kwargs=target_store_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eopf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
